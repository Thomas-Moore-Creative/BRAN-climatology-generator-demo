{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3c7829f-9399-4bfb-adf4-63851ba5fba2",
   "metadata": {},
   "source": [
    "# composited_stats_BRAN2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da85e17d-1666-4bdd-bbb2-ba7288e8e71a",
   "metadata": {},
   "source": [
    "Date: 15 April, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b722e90-e1fa-45a1-9638-5d9732063024",
   "metadata": {},
   "source": [
    "Author = {\"name\": \"Thomas Moore\", \"affiliation\": \"CSIRO\", \"email\": \"thomas.moore@csiro.au\", \"orcid\": \"0000-0003-3930-1946\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23449033-f7fe-4f01-ac2d-de773de8db6b",
   "metadata": {},
   "source": [
    "### BRAN2020 is on the order of 100TB of float data over nearly 9000 `netcdf` file assests in total."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f41a28d-7966-420a-a2ba-5bb53ada1d9c",
   "metadata": {},
   "source": [
    "#### required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbfd2435-2231-4a62-aa70-d5fd531a259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "#more plotting\n",
    "import matplotlib.dates as mdates\n",
    "#import seaborn as sns\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8935960c-d1ab-4b85-8bc4-e2b41de3e910",
   "metadata": {},
   "source": [
    "#### ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "701040b6-201d-4bd9-be1d-2881778a7605",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25d9c26-ad00-4e0a-b8dc-6fcfb15cfc71",
   "metadata": {},
   "source": [
    "#### start a local Dask client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97accd08-fd64-47e2-b870-ed24ff71ad9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask\n",
    "import distributed\n",
    "\n",
    "with dask.config.set({\"distributed.scheduler.worker-saturation\": 1.0,\n",
    "                      \"distributed.nanny.pre-spawn-environ.MALLOC_TRIM_THRESHOLD_\": 0,\n",
    "                    \"logging.distributed\": \"error\"}):\n",
    "    client = distributed.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5503b17d-fda6-4ab3-a465-46398b38e269",
   "metadata": {},
   "source": [
    "# workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d157a-0800-4298-bff5-809c9b4e7572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/es60/users/thomas_moore/miniconda3/envs/pangeo_streamjoy/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n",
      "/g/data/es60/users/thomas_moore/miniconda3/envs/pangeo_streamjoy/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n",
      "/g/data/es60/users/thomas_moore/miniconda3/envs/pangeo_streamjoy/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n",
      "/g/data/es60/users/thomas_moore/miniconda3/envs/pangeo_streamjoy/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n",
      "/g/data/es60/users/thomas_moore/miniconda3/envs/pangeo_streamjoy/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n",
      "/g/data/es60/users/thomas_moore/miniconda3/envs/pangeo_streamjoy/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n",
      "/g/data/es60/users/thomas_moore/miniconda3/envs/pangeo_streamjoy/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n",
      "/g/data/es60/users/thomas_moore/miniconda3/envs/pangeo_streamjoy/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n",
      "/g/data/es60/users/thomas_moore/miniconda3/envs/pangeo_streamjoy/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n"
     ]
    }
   ],
   "source": [
    "### masks for ENSO composites\n",
    "ONI_DF = pd.read_csv('/g/data/xv83/users/tm4888/data/ENSO/NCAR_ONI.csv')\n",
    "ONI_DF.set_index('datetime',inplace=True)\n",
    "ONI_DF.index = pd.to_datetime(ONI_DF.index)\n",
    "el_nino_threshold = 0.5\n",
    "la_nina_threshold = -0.5\n",
    "el_nino_threshold_months = ONI_DF[\"ONI\"].ge(el_nino_threshold)\n",
    "la_nina_threshold_months = ONI_DF[\"ONI\"].le(la_nina_threshold) \n",
    "ONI_DF = pd.concat([ONI_DF, el_nino_threshold_months.rename('El Nino threshold')], axis=1)\n",
    "ONI_DF = pd.concat([ONI_DF, la_nina_threshold_months.rename('La Nina threshold')], axis=1)\n",
    "ONI_DF = pd.concat([ONI_DF, el_nino_threshold_months.diff().ne(0).cumsum().rename('El Nino event group ID')], axis=1)\n",
    "ONI_DF = pd.concat([ONI_DF, la_nina_threshold_months.diff().ne(0).cumsum().rename('La Nina event group ID')], axis=1)\n",
    "#\n",
    "El_Nino_Series = ONI_DF.groupby('El Nino event group ID')['ONI'].filter(lambda x: len(x) >= 5,dropna=False).where(ONI_DF['El Nino threshold'] == True)\n",
    "ONI_DF = pd.concat([ONI_DF, El_Nino_Series.rename('El Nino')], axis=1)\n",
    "La_Nina_Series = ONI_DF.groupby('La Nina event group ID')['ONI'].filter(lambda x: len(x) >= 5,dropna=False).where(ONI_DF['La Nina threshold'] == True)\n",
    "ONI_DF = pd.concat([ONI_DF, La_Nina_Series.rename('La Nina')], axis=1)\n",
    "\n",
    "### run var on what variable\n",
    "#var_name = 'temp'\n",
    "#var_name = 'mld'\n",
    "var_name = 'eta_t'\n",
    "\n",
    "#\n",
    "zarr_path = '/scratch/es60/ard/reanalysis/BRAN2020/ARD/'\n",
    "path_dict = {'eta_t':'BRAN2020-daily-eta_t-chunk4time-v14032024.zarr',\n",
    "                 'mld':'BRAN2020-daily-mld-chunk4time-v04042024.zarr',\n",
    "                 'temp':'BRAN2020-daily-temp-chunk4time-v07022024.zarr'}\n",
    "depth_dict = {'eta_t':None,'mld':None,'temp':'st_ocean'}\n",
    "lon_dict = {'eta_t':'xt_ocean','mld':'xt_ocean','temp':'xt_ocean'}\n",
    "lat_dict = {'eta_t':'yt_ocean','mld':'yt_ocean','temp':'yt_ocean'}\n",
    "time_dim = 'Time'\n",
    "results_path = '/g/data/es60/users/thomas_moore/clim_demo_results/daily/draft_delivery/'\n",
    "results_file = 'BRAN2020_clim_demo_'+var_name+'.nc'\n",
    "collection_path = zarr_path + path_dict[var_name]\n",
    "#\n",
    "ds = xr.open_zarr(collection_path,consolidated=True)\n",
    "clim_ds = xr.merge([ds.groupby(time_dim+'.month').mean(dim=time_dim,engine='flox',method='cohorts').rename({var_name:'mean_'+var_name}),\n",
    "                      ds.groupby(time_dim+'.month').min(dim=time_dim,engine='flox',method='cohorts').rename({var_name:'min_'+var_name}),\n",
    "                      ds.groupby(time_dim+'.month').max(dim=time_dim,engine='flox',method='cohorts').rename({var_name:'max_'+var_name}),\n",
    "                      ds.groupby(time_dim+'.month').std(dim=time_dim).rename({var_name:'std_'+var_name}),\n",
    "                      ds.groupby(time_dim+'.month').median(dim=time_dim).rename({var_name:'median_'+var_name})\n",
    "])\n",
    "quant = ds.groupby(time_dim+'.month').quantile([0.05,0.95],skipna=True,dim=time_dim).astype(np.float32)\n",
    "quant_ds = xr.merge([quant.isel(quantile=0).reset_coords(drop=True).rename({var_name:'quantile_05_'+var_name}),quant.isel(quantile=1).reset_coords(drop=True).rename({var_name:'quantile_95_'+var_name})])\n",
    "result_ds = xr.merge([clim_ds,quant_ds])\n",
    "### ENSO composites\n",
    "# filter BRAN2020 data by ENSO\n",
    "ONI_DF_BRANtime = ONI_DF['1993-01':'2023-06']\n",
    "ONI_DF_BRANtime['El Nino LOGICAL'] = ONI_DF_BRANtime['El Nino'].notnull()\n",
    "ONI_DF_BRANtime['La Nina LOGICAL'] = ONI_DF_BRANtime['La Nina'].notnull()\n",
    "# shift back from middle of month\n",
    "ONI_DF_BRANtime.index += pd.Timedelta(-14, 'd')\n",
    "# modify end value for upsample\n",
    "ONI_DF_BRANtime.loc[pd.to_datetime('2023-07-01 00:00:00')] = 'NaN'\n",
    "#upsample\n",
    "ONI_DF_BRANtime = ONI_DF_BRANtime.resample('D').ffill()\n",
    "#drop last dummy date\n",
    "ONI_DF_BRANtime = ONI_DF_BRANtime[:-1]\n",
    "#\n",
    "El_Nino_mask = ONI_DF_BRANtime['El Nino LOGICAL']\n",
    "El_Nino_mask = El_Nino_mask.to_xarray()\n",
    "El_Nino_mask = El_Nino_mask.rename({'datetime':'Time'})\n",
    "sync_Time = ds.Time\n",
    "El_Nino_mask['Time'] = sync_Time\n",
    "#\n",
    "La_Nina_mask = ONI_DF_BRANtime['La Nina LOGICAL']\n",
    "La_Nina_mask = La_Nina_mask.to_xarray()\n",
    "La_Nina_mask = La_Nina_mask.rename({'datetime':'Time'})\n",
    "sync_Time = ds.Time\n",
    "La_Nina_mask['Time'] = sync_Time\n",
    "#\n",
    "ONI_DF_BRANtime['Neutral LOGICAL'] = (ONI_DF_BRANtime['El Nino LOGICAL'] == False) & (ONI_DF_BRANtime['La Nina LOGICAL'] == False)\n",
    "neutral_mask = ONI_DF_BRANtime['La Nina LOGICAL']\n",
    "neutral_mask = neutral_mask.to_xarray()\n",
    "neutral_mask = neutral_mask.rename({'datetime':'Time'})\n",
    "sync_Time = ds.Time\n",
    "neutral_mask['Time'] = sync_Time\n",
    "\n",
    "### mask out data\n",
    "El_Nino_ds = ds.where(El_Nino_mask)\n",
    "La_Nina_ds = ds.where(La_Nina_mask)\n",
    "neutral_ds = ds.where(neutral_mask)\n",
    "##### El Nino calc\n",
    "clim_El_Nino_ds = xr.merge([El_Nino_ds.groupby(time_dim+'.month').mean(dim=time_dim,engine='flox',method='cohorts').rename({var_name:'mean_'+'el_nino_'+var_name}),\n",
    "                      El_Nino_ds.groupby(time_dim+'.month').min(dim=time_dim,engine='flox',method='cohorts').rename({var_name:'min_'+'el_nino_'+var_name}),\n",
    "                      El_Nino_ds.groupby(time_dim+'.month').max(dim=time_dim,engine='flox',method='cohorts').rename({var_name:'max_'+'el_nino_'+var_name}),\n",
    "                      El_Nino_ds.groupby(time_dim+'.month').std(dim=time_dim).rename({var_name:'std_'+'el_nino_'+var_name}),\n",
    "                      El_Nino_ds.groupby(time_dim+'.month').median(dim=time_dim).rename({var_name:'median_'+'el_nino_'+var_name})\n",
    "])\n",
    "quant_El_Nino = El_Nino_ds.groupby(time_dim+'.month').quantile([0.05,0.95],skipna=True,dim=time_dim).astype(np.float32)\n",
    "quant_El_Nino_ds = xr.merge([quant_El_Nino.isel(quantile=0).reset_coords(drop=True).rename({var_name:'quantile_05_'+'el_nino_'+var_name}),quant_El_Nino.isel(quantile=1).reset_coords(drop=True).rename({var_name:'quantile_95_'+'el_nino_'+var_name})])\n",
    "result_El_Nino_ds = xr.merge([clim_El_Nino_ds,quant_El_Nino_ds])\n",
    "#### La Nina calc\n",
    "clim_La_Nina_ds = xr.merge([La_Nina_ds.groupby(time_dim+'.month').mean(dim=time_dim,engine='flox',method='cohorts').rename({var_name:'mean_'+'la_nina_'+var_name}),\n",
    "                      La_Nina_ds.groupby(time_dim+'.month').min(dim=time_dim,engine='flox',method='cohorts').rename({var_name:'min_'+'la_nina_'+var_name}),\n",
    "                      La_Nina_ds.groupby(time_dim+'.month').max(dim=time_dim,engine='flox',method='cohorts').rename({var_name:'max_'+'la_nina_'+var_name}),\n",
    "                      La_Nina_ds.groupby(time_dim+'.month').std(dim=time_dim).rename({var_name:'std_'+'la_nina_'+var_name}),\n",
    "                      La_Nina_ds.groupby(time_dim+'.month').median(dim=time_dim).rename({var_name:'median_'+'la_nina_'+var_name})\n",
    "])\n",
    "quant_La_Nina = La_Nina_ds.groupby(time_dim+'.month').quantile([0.05,0.95],skipna=True,dim=time_dim).astype(np.float32)\n",
    "quant_La_Nina_ds = xr.merge([quant_La_Nina.isel(quantile=0).reset_coords(drop=True).rename({var_name:'quantile_05_'+'la_nina_'+var_name}),quant_La_Nina.isel(quantile=1).reset_coords(drop=True).rename({var_name:'quantile_95_'+'la_nina_'+var_name})])\n",
    "result_La_Nina_ds = xr.merge([clim_La_Nina_ds,quant_La_Nina_ds])\n",
    "#### neutral calc\n",
    "clim_neutral_ds = xr.merge([neutral_ds.groupby(time_dim+'.month').mean(dim=time_dim,engine='flox',method='cohorts').rename({var_name:'mean_'+'neutral_'+var_name}),\n",
    "                      neutral_ds.groupby(time_dim+'.month').min(dim=time_dim,engine='flox',method='cohorts').rename({var_name:'min_'+'neutral_'+var_name}),\n",
    "                      neutral_ds.groupby(time_dim+'.month').max(dim=time_dim,engine='flox',method='cohorts').rename({var_name:'max_'+'neutral_'+var_name}),\n",
    "                      neutral_ds.groupby(time_dim+'.month').std(dim=time_dim).rename({var_name:'std_'+'neutral_'+var_name}),\n",
    "                      neutral_ds.groupby(time_dim+'.month').median(dim=time_dim).rename({var_name:'median_'+'neutral_'+var_name})\n",
    "])\n",
    "quant_neutral = neutral_ds.groupby(time_dim+'.month').quantile([0.05,0.95],skipna=True,dim=time_dim).astype(np.float32)\n",
    "quant_neutral_ds = xr.merge([quant_neutral.isel(quantile=0).reset_coords(drop=True).rename({var_name:'quantile_05_'+'neutral_'+var_name}),quant_neutral.isel(quantile=1).reset_coords(drop=True).rename({var_name:'quantile_95_'+'neutral_'+var_name})])\n",
    "result_neutral_ds = xr.merge([clim_neutral_ds,quant_neutral_ds])\n",
    "#\n",
    "result_ds = xr.merge([result_ds,result_El_Nino_ds,result_La_Nina_ds,result_neutral_ds])\n",
    "\n",
    "# # netcdf4 settings & chunking\n",
    "# compression_opts = {\n",
    "#     'zlib': True,      # Enable compression\n",
    "#     'complevel': 1,    # Set a moderate compression level\n",
    "#     'chunksizes': None,  # adjust based on your data's dimensions\n",
    "# }\n",
    "\n",
    "# # Apply the same compression options to all variables for simplicity\n",
    "# encoding = {var: compression_opts for var in result_ds.data_vars}\n",
    "\n",
    "# # Save to a NetCDF file with compression\n",
    "# result_ds.to_netcdf(results_path+results_file,engine='netcdf4',encoding=encoding)\n",
    "\n",
    "result_ds.to_netcdf(results_path+results_file,engine='netcdf4')\n",
    "\n",
    "# Write log file\n",
    "log_path = '/scratch/es60/ard/reanalysis/BRAN2020/ARD/logs/'\n",
    "log_file = log_path + f'log_{datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\")}_{var_name}_stats.txt'\n",
    "with open(log_file, 'a') as f:\n",
    "    f.write(f'{var_name} processing finished\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a9d5ae-fe32-45d2-9af6-6d13ea3ac988",
   "metadata": {},
   "source": [
    "# $The$ $End$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1920d781-f954-436b-94a8-f58d899f5150",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7fd9c2-7539-4b55-b7b0-4f05c78bba27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
