{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3c7829f-9399-4bfb-adf4-63851ba5fba2",
   "metadata": {},
   "source": [
    "# make netcdf GIS ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da85e17d-1666-4bdd-bbb2-ba7288e8e71a",
   "metadata": {},
   "source": [
    "Date: 8 June, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b722e90-e1fa-45a1-9638-5d9732063024",
   "metadata": {},
   "source": [
    "Author = {\"name\": \"Thomas Moore\", \"affiliation\": \"CSIRO\", \"email\": \"thomas.moore@csiro.au\", \"orcid\": \"0000-0003-3930-1946\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23449033-f7fe-4f01-ac2d-de773de8db6b",
   "metadata": {},
   "source": [
    "### BRAN2020 is on the order of 50TB of float data over nearly 9000 `netcdf` file assests in total."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f41a28d-7966-420a-a2ba-5bb53ada1d9c",
   "metadata": {},
   "source": [
    "#### required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfd2435-2231-4a62-aa70-d5fd531a259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import dask\n",
    "import datetime\n",
    "import zarr\n",
    "\n",
    "from rechunker import rechunk\n",
    "\n",
    "import gc\n",
    "import sys\n",
    "import subprocess\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "import glob\n",
    "import streamjoy\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111ad10a-4e8b-4644-8198-fd7bfe21bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the directory of the module to sys.path - import functions\n",
    "sys.path.append('/g/data/es60/users/thomas_moore/code/Climatology-generator-demo/src/')\n",
    "import bran2020_demo_functions as my_tools\n",
    "from bran2020_demo_functions import keep_only_selected_vars, load_rechunker_config, print_chunks, rechunk_each_st_ocean, remove_zarr_encoding, version_table, concatinate_st_ocean_zarrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25d9c26-ad00-4e0a-b8dc-6fcfb15cfc71",
   "metadata": {},
   "source": [
    "#### start a local Dask client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97accd08-fd64-47e2-b870-ed24ff71ad9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set configuration options\n",
    "dask.config.set({\n",
    "    'distributed.comm.timeouts.connect': '90s',  # Timeout for connecting to a worker\n",
    "    'distributed.comm.timeouts.tcp': '90s',  # Timeout for TCP communications\n",
    "})\n",
    "\n",
    "cluster = LocalCluster(\n",
    "    n_workers=14,          # Number of workers\n",
    "    threads_per_worker=1#,\n",
    "    #memory_limit='8GB' # Memory limit per each worker\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d34bf0-3ad5-405a-b5dc-06a8f233caea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary\n",
    "dynamic_ds = {}\n",
    "\n",
    "# Define your var and phase lists\n",
    "var_values = ['temp', 'salt','u','v','eta_t','mld']  # replace with your actual list\n",
    "#var_values = ['u']\n",
    "phase_values = ['alltime', 'neutral','la_nina','el_nino']  # replace with your actual list\n",
    "\n",
    "# Iterate over all combinations of var and phase\n",
    "for var_name in var_values:\n",
    "    for phase_name in phase_values:\n",
    "        # Generate the object name\n",
    "        ds_name = f'{var_name}_{phase_name}_ds'\n",
    "        \n",
    "        # Store the value in the dictionary\n",
    "        results_path = '/g/data/es60/users/thomas_moore/clim_demo_results/daily/bran2020_intermediate_results/'\n",
    "        files = glob.glob(results_path+'*_'+var_name+'_*'+phase_name+'*.nc')\n",
    "        sorted_files = sorted(files, key=os.path.getctime)\n",
    "        #print('>>>>> '+var_name+'&'+phase_name+' <<<<<')\n",
    "        #print(sorted_files)\n",
    "        \n",
    "        dynamic_ds[ds_name] = xr.open_mfdataset(files,parallel=True)  # replace with your actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10462316-f780-4f60-8fef-a105b9b9d663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the phase string to the name of all variables in each dataset\n",
    "for ds_name, dataset in dynamic_ds.items():\n",
    "    # Get the phase name from the dataset name\n",
    "    phase_name = '_'.join(ds_name.split('_')[1:-1])\n",
    "    if phase_name not in phase_values:\n",
    "        phase_name = '_'.join(ds_name.split('_')[2:-1])\n",
    "    if phase_name in phase_values:\n",
    "        # Add the phase string to the name of all variables\n",
    "        for var_name in dataset.data_vars:\n",
    "            new_var_name = f'{var_name}_{phase_name}'\n",
    "            dataset = dataset.rename({var_name: new_var_name})\n",
    "        dynamic_ds[ds_name] = dataset\n",
    "    else:\n",
    "        print(f\"No match found for phase name: {phase_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f692981-e243-464d-a097-7fe8f78ce8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_datasets = {}\n",
    "for var_name in var_values:\n",
    "        # Get all datasets with the same var_name\n",
    "        var_datasets = [dataset for ds_name, dataset in dynamic_ds.items() if var_name+'_' in ds_name]\n",
    "        \n",
    "        # Merge the datasets along the time dimension\n",
    "        merged_dataset = xr.merge(var_datasets)\n",
    "        \n",
    "        # Store the merged dataset in the dictionary\n",
    "        merged_datasets[var_name] = merged_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644a7e04-4b47-4de6-93f8-0eaa7accca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total size of all datasets in the dictionary\n",
    "total_size_gb = sum(merged_dataset.nbytes / (1024**3) for merged_dataset in merged_datasets.values())\n",
    "print(f\"Total size of all datasets: {total_size_gb} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f04e75-49c5-451c-adb2-2db1709acb7a",
   "metadata": {},
   "source": [
    "##### `/g/data/es60/users/thomas_moore/clim_demo_results/daily/bran2020_intermediate_results du -hsc *.nc` = 532G\ttotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c80d31-e88d-4a38-a6bb-532d262b0db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the keys for the dynamic_ds dictionary\n",
    "print(merged_datasets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af87460-9265-48c0-9096-bef6a9f2cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lazy load each dataset\n",
    "lazy_datasets = {}\n",
    "for var_name, merged_dataset in merged_datasets.items():\n",
    "    #print([var_name,merged_dataset])\n",
    "    lazy_datasets[var_name] = merged_dataset\n",
    "\n",
    "lazy_datasets.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ed953f-5307-4ca1-a202-1b3432346d6e",
   "metadata": {},
   "source": [
    "## coordinate nomeclature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110a4372-53bd-4416-89cd-d63e44543123",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_names = {\n",
    "    \"lat_name_dict\": {\n",
    "        \"temp\": \"yt_ocean\",\n",
    "        \"salt\": \"yt_ocean\",\n",
    "        \"u\": \"yu_ocean\",\n",
    "        \"v\": \"yu_ocean\",\n",
    "        \"mld\": \"yt_ocean\",\n",
    "        \"eta_t\": \"yt_ocean\"\n",
    "    },\n",
    "    \"lon_name_dict\": {\n",
    "        \"temp\": \"xt_ocean\",\n",
    "        \"salt\": \"xt_ocean\",\n",
    "        \"u\": \"xu_ocean\",\n",
    "        \"v\": \"xu_ocean\",\n",
    "        \"mld\": \"xt_ocean\",\n",
    "        \"eta_t\": \"xt_ocean\"\n",
    "    },\n",
    "    \"depth_name_dict\": {\n",
    "        \"temp\": \"st_ocean\",\n",
    "        \"salt\": \"st_ocean\",\n",
    "        \"u\": \"st_ocean\",\n",
    "        \"v\": \"st_ocean\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6c65cd-1e4a-4e7f-94c0-84007b335d5c",
   "metadata": {},
   "source": [
    "# prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133d94fc-916d-463e-823a-f0e41f265fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_variable_list = ['mld','eta_t','temp','salt','u','v']\n",
    "phase_list = ['alltime','el_nino','la_nina','neutral']\n",
    "statistics_list = ['mean','std','min','max','median','quantile_05','quantile_95']\n",
    "\n",
    "# Create a list of all possible combinations of variable and statistics and phase\n",
    "statistics_core_variable_phase_list = [(statistic, core_variable, phase) for core_variable in core_variable_list for statistic in statistics_list for phase in phase_list]\n",
    "print(statistics_core_variable_phase_list)\n",
    "print(len(statistics_core_variable_phase_list))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae3da597-3286-4c96-b802-1aa6611ed8c0",
   "metadata": {},
   "source": [
    "datasets = {'mld':lazy_datasets['mld'],'eta_t':lazy_datasets['eta_t'],'temp':lazy_datasets['temp'],'salt':lazy_datasets['salt'],'u':lazy_datasets['u'],'v':lazy_datasets['v']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d277023b-ec5d-413a-a3d9-ea8c8d36a4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_core_variable_phase_string_list = [f\"{statistic}_{core_variable}_{phase}\" for statistic, core_variable, phase in statistics_core_variable_phase_list]\n",
    "print(statistics_core_variable_phase_string_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ce1bc1-003c-4ee9-bac6-18cf04376d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable_name in statistics_core_variable_phase_string_list:\n",
    "    found_variable = None\n",
    "    for dataset_name, dataset in lazy_datasets.items():\n",
    "        if variable_name in dataset.variables:\n",
    "            found_variable = dataset[variable_name]\n",
    "            break\n",
    "    if found_variable is not None:\n",
    "        print(f\"Variable '{variable_name}' found in dataset '{dataset_name}'\")\n",
    "    else:\n",
    "        print(f\"Variable '{variable_name}' not found in any dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfb971b-4b80-482f-9cd3-0e4dd5a9bc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder structure\n",
    "folder_structure = {}\n",
    "base_folder_name = 'BRAN2020_climatology'\n",
    "folder_structure[base_folder_name] = {}\n",
    "for phase in phase_list:\n",
    "    folder_structure[base_folder_name][phase] = {}\n",
    "    for core_variable in core_variable_list:\n",
    "        folder_structure[base_folder_name][phase][core_variable] = {}\n",
    "\n",
    "folder_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7495e99b-dfd3-4a9b-af51-4194d8871147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_paths(folder_structure, parent_path=''):\n",
    "    paths = []\n",
    "    for folder_name, subfolders in folder_structure.items():\n",
    "        current_path = f\"{parent_path}/{folder_name}\" if parent_path else folder_name\n",
    "        paths.append(current_path)\n",
    "        if subfolders:\n",
    "            paths.extend(get_folder_paths(subfolders, current_path))\n",
    "    return paths\n",
    "\n",
    "folder_paths = get_folder_paths(folder_structure)\n",
    "print(folder_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dbd91d-9b23-46fb-b76b-3b84885fe687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder_structure(base_path, folder_structure):\n",
    "    for folder_name, subfolders in folder_structure.items():\n",
    "        current_path = os.path.join(base_path, folder_name)\n",
    "        os.makedirs(current_path, exist_ok=True)\n",
    "        if subfolders:\n",
    "            create_folder_structure(current_path, subfolders)\n",
    "\n",
    "# Example usage\n",
    "base_path = '/scratch/es60/thomas_moore/bran2020_GISready_delivery'\n",
    "\n",
    "\n",
    "create_folder_structure(base_path, folder_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b6a9ba-e875-4fca-90a6-2240a98a9097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_paths(folder_structure, parent_path=''):\n",
    "    paths = []\n",
    "    for folder_name, subfolders in folder_structure.items():\n",
    "        current_path = f\"{parent_path}/{folder_name}\" if parent_path else folder_name\n",
    "        paths.append(current_path)\n",
    "        if subfolders:\n",
    "            paths.extend(get_folder_paths(subfolders, current_path))\n",
    "    return paths\n",
    "\n",
    "folder_paths = get_folder_paths(folder_structure)\n",
    "print(folder_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ed2a26-f9a4-4d38-b201-fb351e7d6122",
   "metadata": {},
   "outputs": [],
   "source": [
    "GISready_datasets = {}\n",
    "for core_variable in core_variable_list:\n",
    "    for phase in phase_list:\n",
    "        dataset_name = f\"{core_variable}_{phase}\"\n",
    "        GISready_datasets[dataset_name] = []\n",
    "        for variable_name in statistics_core_variable_phase_string_list:\n",
    "            if core_variable+'_' in variable_name and phase in variable_name:\n",
    "                found_variable = None\n",
    "                for core_dataset_name, dataset in lazy_datasets.items():\n",
    "                    if variable_name in dataset.data_vars:\n",
    "                        found_variable = dataset[variable_name]\n",
    "                        break\n",
    "                if found_variable is not None:\n",
    "                    GISready_datasets[dataset_name].append(found_variable)\n",
    "                else:\n",
    "                    print(f\"Variable '{variable_name}' not found in any dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8a4487-f8bf-4ac1-a542-f398be88af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.merge(GISready_datasets['u_alltime']).isel(month=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c780d4-5d2e-4a03-96b9-8c5e00cc950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_string = \"temp_\"  # Replace \"string\" with the desired search string\n",
    "matching_datasets = [dataset_name for dataset_name in GISready_datasets.keys() if search_string in dataset_name]\n",
    "print(matching_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694fc783-a667-444c-9233-7fd5169b0b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a list comprehension to get the values for the keys in the list\n",
    "list_list_of_DA = [GISready_datasets[key] for key in matching_datasets if key in GISready_datasets]\n",
    "flattened_list_of_DA = [item for sublist in list_list_of_DA for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae88bb30-1279-44d5-9ed0-7c72cc633a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.merge(flattened_list_of_DA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ea4e7-7411-407b-85cf-6570ce79abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for core_variable in core_variable_list:\n",
    "    for phase in phase_list:\n",
    "        print(phase + core_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcb9eaa-2ac0-4108-a9e3-c67373506f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e0cc53-f566-47bb-8eaf-baf331c11ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7805507d-5c2f-46c1-96ea-ca015a84b775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f289eaa8-8a45-43c0-b21b-d3062323d54d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde46a8d-d55a-4fd4-b259-ddd913f73f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b4110c-b795-4c70-80f3-edd59244d668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa5b43d-e9da-4f8a-bb6f-ced40de32e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd551b7b-fa17-46f3-8c74-eee7b51c8ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "965e59d9-3c0b-4739-a411-d4534a9faa86",
   "metadata": {},
   "source": [
    "# rechunk all the datasets for 1,1,300,300, or 1,300,300"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c3b578e2-6046-423e-9e62-aa5dd7e77103",
   "metadata": {},
   "source": [
    "rechunked_datasets = {}\n",
    "for var_name, lazy_dataset in lazy_datasets.items():\n",
    "    rechunked_dataset = lazy_dataset\n",
    "    if var_name in coordinate_names['depth_name_dict']:\n",
    "        depth_coord = coordinate_names['depth_name_dict'][var_name]\n",
    "        rechunked_dataset = rechunked_dataset.chunk({depth_coord: 1})\n",
    "    if var_name in coordinate_names['lon_name_dict']:\n",
    "        lon_coord = coordinate_names['lon_name_dict'][var_name]\n",
    "        rechunked_dataset = rechunked_dataset.chunk({lon_coord: 300})\n",
    "    if var_name in coordinate_names['lat_name_dict']:\n",
    "        lat_coord = coordinate_names['lat_name_dict'][var_name]\n",
    "        rechunked_dataset = rechunked_dataset.chunk({lat_coord: 300})\n",
    "    rechunked_dataset = rechunked_dataset.chunk({'month': 1})\n",
    "    rechunked_datasets[var_name] = rechunked_dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ad52eed-45cc-44f4-9bb2-f08e8acb0761",
   "metadata": {},
   "source": [
    "write_var = 'eta_t'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5023a06-1516-452e-947c-d6bb283c8b1b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%%time\n",
    "write_this = rechunked_datasets[write_var].compute()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "939d6336-4084-40cb-9b5b-9c92de381aa9",
   "metadata": {},
   "source": [
    "%%time\n",
    "encoding = {} #setup encoding dict\n",
    "chunksizes_tuple = (1, 300, 300)  # set default 2D chunksizes for netcdf write\n",
    "\n",
    "# Check if 'mld' is present in the 'st_ocean' subdictionary\n",
    "if write_var in coordinate_names['depth_name_dict']:\n",
    "    chunksizes_tuple = (1, 1, 300, 300)  # set chunksizes for 3D variable\n",
    "for var_name in write_this.data_vars:\n",
    "    encoding[var_name] = {'zlib': True, 'complevel': 5, 'dtype': 'float32', 'chunksizes': chunksizes_tuple} # encode only the data variables\n",
    "# Save to NetCDF with chunking and compression encoding\n",
    "write_this.to_netcdf('/g/data/es60/users/thomas_moore/clim_demo_results/daily/bran2020_final_results/bran2020_'+write_var+'_ENSO_stats.nc',\n",
    "                         engine='netcdf4',encoding=encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a9d5ae-fe32-45d2-9af6-6d13ea3ac988",
   "metadata": {},
   "source": [
    "# $The$ $End$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1920d781-f954-436b-94a8-f58d899f5150",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7fd9c2-7539-4b55-b7b0-4f05c78bba27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d5627a-1ebf-49ff-8a7b-dd81b71e1d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28effe3b-109d-44ed-8a88-5698ca515f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198ec405-397c-4fb7-a09f-3771a2605ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd12f341-7ea0-40d4-95cf-42f8f38c99ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81577acc-6064-4bd0-b4c0-892a40687747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a457236-0174-4a5f-8c08-519d260a35c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b9d87a-6560-490c-b056-4dbd86a22fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf619d6-8115-47a2-86fc-6b8586093a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2fc7cb-828f-4eef-9daf-df4c84140f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c2dd5b-620d-421a-80cf-8858bb56c3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac756698-03c0-49d8-82a9-f465bed60e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a33e2-1959-40bf-8b0c-2b30a902cbbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a53d0a5-fd30-4537-8f27-3eb7ad3c7eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89badcb-5c83-4208-ac41-b2955e1a91f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120bee30-dad5-4576-9e91-1e20838903a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431cc5d2-a971-489c-895d-44be12a04f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3243ef59-8e3d-49ac-9ef9-3e819a53a11c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff6a4ba4-1cdc-4ec8-a1a9-4942d35a44ea",
   "metadata": {},
   "source": [
    "## Plot current vectors for August"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3619d6-6f06-48c4-8692-b42e40d2b067",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)\n",
    "import matplotlib.ticker as ticker\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy\n",
    "from matplotlib import mlab, cm, gridspec\n",
    "import matplotlib.ticker as mticker\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a7c5ed-a1b6-4ab4-81ad-f0ca978480b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Define the u and v components of the currents\n",
    "time_choice = 8\n",
    "u = clim_uv.u.sel(month=time_choice)\n",
    "v = clim_uv.v.sel(month=time_choice)\n",
    "speed = np.sqrt(u**2 + v**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6966cd-1bb5-4248-9933-1522076e8417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot model data\n",
    "transform = ccrs.PlateCarree()\n",
    "cmap = 'Spectral_r'\n",
    "cbar_label='current speed'\n",
    "plot_data = speed\n",
    "\n",
    "###\n",
    "fig = plt.figure(num=None, figsize=(8, 6), dpi=300, facecolor='w', edgecolor='k')\n",
    "ax = plt.subplot(projection=ccrs.PlateCarree(180))\n",
    "ax.set_extent([142,160, -25, -10], ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '50m', edgecolor='face', facecolor='white'))\n",
    "ax.coastlines('50m',linewidth=0.5,edgecolor='grey')\n",
    "plot_data.plot(transform=transform,cmap=cmap,cbar_kwargs={'label': cbar_label,'shrink':0.5},robust=True)\n",
    "\n",
    "#plot u/v vectors\n",
    "# Define the x and y coordinates\n",
    "x = clim_uv.xu_ocean\n",
    "y = clim_uv.yu_ocean\n",
    "ax.quiver(x.values,y.values,u.values,v.values,transform=transform, units='x', width=0.01, scale=0.7, headwidth=2,alpha=0.2)\n",
    "ax.set_title('BRAN2020 1993-2022\\ncurrent speed \\n August Climatology')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
